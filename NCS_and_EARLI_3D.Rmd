---
title: "Placenta Analysis 2"
author: "Ilya Kukovitskiy"
date: "July 6, 2018"
output: html_document
self_contained: no
---

```{r,results='hide',message=FALSE}
set.seed(1)
library(tree)
library(randomForest)
library(gbm)
library(ggplot2)
library(tree)
library("fitdistrplus")
library(tibble)
```

# NYMH x10 and x20

## Data Preprocessing

### Reading in and storing datasets from file

```{r}
df <- read.csv('NCS_and_EARLI_Data_updated_5_19_2016JMC.csv')
```

#### Seems like some variable are not useful, like Placenta ID, that should be treated specially and/or removed. There are several alphabets of columns. Viewing number of NAs in each column:

```{r}
sapply(df, function(x) sum(is.na(x)))
# The only variables with NAs are: BW_g, PW_g, GA_wk, Gender, and Calculated.Beta:
NAs <- df[,c('BW_g', 'PW_g', 'GA_wk', 'Gender', 'Calculated.Beta')]
sapply(NAs, function(x) sum(is.na(x)))
```

The variables with NAs are: Birth Weight, Placental Weight, Gestational Age, Gender, and the log ratio of Placental to Birth Weight. 

#### (Gestational Age is extremely important in a pregnancy?) And 176 entries would be removed. Instead, the average for the group NCS or EARLI will be computed for each NA.

```{r}
# average for 1
X1 <- NULL
for(i in which(df[,1]==1)){X1<-rbind(X1,df[i,])}
avg1 <- mean(X1$GA_wk, na.rm=TRUE)
# average for 2
X2 <- NULL
for(i in which(df[,1]==2)){X2<-rbind(X2,df[i,])}
avg2 <- mean(X2$GA_wk, na.rm=TRUE)

# replacing NAs with avg1
for(i in which(df[,1]==1)){
  if(is.na(df$GA_wk[i])){
    df$GA_wk[i] <- avg1
  }
}
# replacing NAs with avg2
for(i in which(df[,1]==2)){
  if(is.na(df$GA_wk[i])){
    df$GA_wk[i] <- avg2
  }
}
```

#### Beta NAs include all NAs from either Birth or Placental Weight, and also highly coincide with Gender NAs. Removing these observations.

```{r}
df <- na.omit(df)
```

#### Logistic Regression Requires 0s and 1s. Subtracting 1 from all NCS or EARLI values

```{r}
df[,1] <- df[,1]-1
```

## Data Analysis - Clustering



```{r}

```


## Data Analysis - Prediction



### Simple Logistic Regression

```{r}
#initial logistic regression
glm <- glm(ï..NCS.or.EARLI~.-Placenta.ID, data=df, family='binomial')
summary(glm)
```

#### Training and Testing Logistic Regression

```{r}

```


#### Simple Decision Tree

```{r}
#tree() can only handle 32 levels on factor predictors

names(Filter(is.factor, df)) #taking a look at which variables have factors - 
#nlevels(scene_name) #scene_name has 811 levels - too many to grow trees on
View(scene_name) #just names of trials - removing this variable
#colnames(df)
df <- df[,-1]

#initial decision tree
tree <- tree(EARLI~., data=df)
#Plotting Tree
plot(tree)

##
#View(tree)
#View(tree$frame)

#tree.pred <- predict(tree, type="class")

```

